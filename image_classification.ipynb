{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OozM1HKYJ5T9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score  \n",
        "torch.manual_seed(101)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QRnWJMLD77t",
        "outputId": "2b478868-a496-40c7-9f71-5bfc9d1ab188"
      },
      "outputs": [],
      "source": [
        "Transform = transforms.ToTensor()\n",
        "train = datasets.MNIST(root='../DATA', train=True, download=False, transform=Transform)\n",
        "test = datasets.MNIST(root='../DATA', train=False, download=False, transform=Transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1)Multi Layer Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultilayerNetwork_v1(nn.Module):\n",
        "    '''1 Hidden Layer with 80 neurons'''\n",
        "    def __init__(self, input_size=784, output_size=10, layers=[100]) -> None:\n",
        "        super().__init__()\n",
        "        self.h1 = nn.Linear(input_size, layers[0])\n",
        "        self.predict = nn.Linear(layers[0], output_size)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = X.view(-1,28 * 28)\n",
        "        X = F.relu(self.h1(X))\n",
        "        X = self.predict(X)\n",
        "        return X\n",
        "\n",
        "class MultilayerNetwork_v2(nn.Module):\n",
        "    '''1 Hidden Layer with 50 neurons'''\n",
        "    def __init__(self, input_size=784, output_size=10, layers=[50]) -> None:\n",
        "        super().__init__()\n",
        "        self.h1 = nn.Linear(input_size, layers[0])\n",
        "        self.predict = nn.Linear(layers[0], output_size)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = X.view(-1,28 * 28)\n",
        "        X = F.relu(self.h1(X))\n",
        "        X = self.predict(X)\n",
        "        return X\n",
        "\n",
        "class MultilayerNetwork_v3(nn.Module):\n",
        "    '''2 Hidden Layers with 100 neurons'''\n",
        "    def __init__(self, input_size=784, output_size=10, layers=[100,100]) -> None:\n",
        "        super().__init__()\n",
        "        self.h1 = nn.Linear(input_size, layers[0])\n",
        "        self.h2 = nn.Linear(layers[0], layers[1])\n",
        "        self.predict = nn.Linear(layers[1], output_size)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = X.view(-1,28 * 28)\n",
        "        X = F.relu(self.h1(X))\n",
        "        X = F.relu(self.h2(X))\n",
        "        X = self.predict(X)\n",
        "        return X\n",
        "\n",
        "class CNN_1(nn.Module):\n",
        "    '''Conv -> RELU -> Max_Pool -> Conv ->RELU -> Max_Pool -> FC '''\n",
        "    def __init__(self):\n",
        "        super(CNN_1, self).__init__() \n",
        "               \n",
        "        self.conv1 = nn.Sequential(         \n",
        "            nn.Conv2d(\n",
        "                in_channels=1,              \n",
        "                out_channels=16,            \n",
        "                kernel_size=5,              \n",
        "                stride=1,                   \n",
        "                padding=2,                  \n",
        "            ),                              \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(kernel_size=2),    \n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(         \n",
        "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(2),                \n",
        "        )        \n",
        "        \n",
        "        self.out = nn.Linear(32 * 7 * 7, 10)    \n",
        "        \n",
        "    def forward(self, X):\n",
        "        X = self.conv1(X)\n",
        "        X = self.conv2(X)        \n",
        "        # flatten the output \n",
        "        X = X.view(X.size(0), -1)       \n",
        "        X = self.out(X)\n",
        "        return X    \n",
        "\n",
        "class CNN_2(nn.Module):\n",
        "    '''Conv -> RELU -> Max_Pool -> Conv ->RELU -> Max_Pool -> FC -> RELU -> FC  with dropoutt='''\n",
        "    def __init__(self):\n",
        "        super(CNN_2, self).__init__() \n",
        "               \n",
        "        self.conv1 = nn.Sequential(         \n",
        "            nn.Conv2d(\n",
        "                in_channels=1,              \n",
        "                out_channels=12,            \n",
        "                kernel_size=3,              \n",
        "                stride=1,                   \n",
        "                padding=1,                  \n",
        "            ),                              \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(kernel_size=2),    \n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(         \n",
        "            nn.Conv2d(12, 24, 3, 1, 1),     \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(2),                \n",
        "        )        \n",
        "        \n",
        "        self.out_layers = nn.Sequential(\n",
        "            nn.Linear(24 * 7 * 7, 64), \n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2), #dropout with probability .2 to prevent overfitting\n",
        "            nn.Linear(64, 10),  \n",
        "        ) \n",
        "        \n",
        "    def forward(self, X):\n",
        "        X = self.conv1(X)\n",
        "        X = self.conv2(X)        \n",
        "        # flatten the output \n",
        "        X = X.view(X.size(0), -1)       \n",
        "        X = self.out_layers(X)\n",
        "        return X \n",
        "\n",
        "\n",
        "class CNN_3(nn.Module):\n",
        "    \"\"\"Conv -> RELU -> Max_Pool -> Conv ->RELU -> Max_Pool -> FC -> RELU -> FC -> SOFTMAX\"\"\"\n",
        "    def __init__(self):\n",
        "        super(CNN_3, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 20, 5, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        \n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(20, 50, 5, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2), \n",
        "        ) \n",
        "\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(4*4*50, 500),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        \n",
        "\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(500, 10),\n",
        "            nn.LogSoftmax()\n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.conv1(X)\n",
        "        X = self.conv2(X)\n",
        "        X = X.view(-1, 4*4*50)\n",
        "        X = self.fc1(X)\n",
        "        X = self.fc2(X)\n",
        "        return X\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This is were you select the model that we want to use from above\n",
        "# model = MultilayerNetwork_v1()\n",
        "# model = MultilayerNetwork_v2()\n",
        "# model = MultilayerNetwork_v3()\n",
        "# model = CNN_1()\n",
        "# model = CNN_2()\n",
        "model = CNN_3()\n",
        "\n",
        "print(model)\n",
        "criterion = nn.CrossEntropyLoss() #loss function criterion\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=.001) #optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 10 # set the number of epochs\n",
        "trainloader = torch.utils.data.DataLoader(train, batch_size=64,shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test, batch_size=64,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, n_epoch=10):\n",
        "    print(model)\n",
        "    model.train()\n",
        "    loss_history = []\n",
        "    for epoch in range(n_epoch):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in trainloader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(images)\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            \n",
        "        running_loss = running_loss/len(trainloader.dataset)\n",
        "        loss_history.append(running_loss)\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
        "            epoch+1, \n",
        "            running_loss\n",
        "            ))\n",
        "    plt.plot(range(len(loss_history)), loss_history)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss over training')\n",
        "        \n",
        "\n",
        "def test(model):\n",
        "    correct_counts = list(0. for i in range(10))\n",
        "    total_counts = list(0. for i in range(10))\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    predicted = []\n",
        "    actual = []\n",
        "    for images, labels in testloader:\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        test_loss += loss.item() * images.size(0)\n",
        "        _, pred = torch.max(output, 1)\n",
        "        correct = np.squeeze(pred.eq(labels.data.view_as(pred)))\n",
        "        for i in range(len(labels.data)): \n",
        "            label = labels.data[i]\n",
        "            actual.append(label)\n",
        "            correct_counts[label] += correct[i].item()\n",
        "            predicted.append(pred[i])\n",
        "            total_counts[label] += 1\n",
        "        \n",
        "    test_loss = test_loss/len(testloader.dataset)\n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    for i in range(10):\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (str(i), 100 * correct_counts[i] / total_counts[i], np.sum(correct_counts[i]), np.sum(total_counts[i])))\n",
        "\n",
        "    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "        100. * np.sum(correct_counts) / np.sum(total_counts),\n",
        "        np.sum(correct_counts), np.sum(total_counts)))\n",
        "    print('Confusion Matrix: \\n')\n",
        "    print(confusion_matrix(predicted, actual))\n",
        "    precision_scores = precision_score(predicted, actual, average=None)\n",
        "    recall_scores = recall_score(predicted, actual, average=None)\n",
        "    f1_scores =  f1_score(predicted, actual, average=None)\n",
        "    print('Class \\t Precision \\t\\t\\t Recall \\t\\t\\t\\t\\t F1')\n",
        "    for i in range(len(precision_scores)):\n",
        "        print(i, '\\t', precision_scores[i], '\\t', recall_scores[i], '\\t', f1_scores[i])\n",
        "    \n",
        "    print('Macro-F1: ', f1_score(predicted, actual, average='macro'))\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train and Test the network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test(model)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "image-classification.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
